--- contrib/python/scikit-learn/py3/sklearn/svm/src/liblinear/liblinear_helper.c	(index)
+++ contrib/python/scikit-learn/py3/sklearn/svm/src/liblinear/liblinear_helper.c	(working tree)
@@ -124,6 +124,7 @@ static struct feature_node **csr_to_sparse(char *x, int double_precision,
     return sparse;
 }
 
+static
 struct problem * set_problem(char *X, int double_precision_X, int n_samples,
         int n_features, int n_nonzero, double bias, char* sample_weight,
         char *Y)
@@ -148,6 +149,7 @@ struct problem * set_problem(char *X, int double_precision_X, int n_samples,
     return problem;
 }
 
+static
 struct problem * csr_set_problem (char *X, int double_precision_X,
         char *indices, char *indptr, int n_samples, int n_features,
         int n_nonzero, double bias, char *sample_weight, char *Y)
@@ -173,6 +175,7 @@ struct problem * csr_set_problem (char *X, int double_precision_X,
 
 
 /* Create a parameter struct with and return it */
+static
 struct parameter *set_parameter(int solver_type, double eps, double C,
                                 npy_intp nr_weight, char *weight_label,
                                 char *weight, int max_iter, unsigned seed, 
@@ -204,6 +207,7 @@ double get_bias(struct model *model)
     return model->bias;
 }
 
+static
 void free_problem(struct problem *problem)
 {
     free(problem->x[0]);
@@ -211,6 +215,7 @@ void free_problem(struct problem *problem)
     free(problem);
 }
 
+static
 void free_parameter(struct parameter *param)
 {
     free(param);
@@ -226,6 +231,7 @@ static void print_string_stdout(const char *s)
 }
 
 /* provide convenience wrapper */
+static
 void set_verbosity(int verbosity_flag){
     if (verbosity_flag)
         set_print_string_function(&print_string_stdout);
--- contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/libsvm_helper.c	(index)
+++ contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/libsvm_helper.c	(working tree)
@@ -30,6 +30,7 @@
  * contiguous, but in practice its a reasonable assumption.
  *
  */
+static
 struct svm_node *dense_to_libsvm (double *x, npy_intp *dims)
 {
     struct svm_node *node;
@@ -55,6 +56,7 @@ struct svm_node *dense_to_libsvm (double *x, npy_intp *dims)
 /*
  * Fill an svm_parameter struct.
  */
+static
 void set_parameter(struct svm_parameter *param, int svm_type, int kernel_type, int degree,
 		double gamma, double coef0, double nu, double cache_size, double C,
 		double eps, double p, int shrinking, int probability, int nr_weight,
@@ -82,6 +84,7 @@ void set_parameter(struct svm_parameter *param, int svm_type, int kernel_type, i
 /*
  * Fill an svm_problem struct. problem->x will be malloc'd.
  */
+static
 void set_problem(struct svm_problem *problem, char *X, char *Y, char *sample_weight, npy_intp *dims, int kernel_type)
 {
     if (problem == NULL) return;
@@ -104,6 +107,7 @@ void set_problem(struct svm_problem *problem, char *X, char *Y, char *sample_wei
  * data structure.
  *
  */
+static
 struct svm_model *set_model(struct svm_parameter *param, int nr_class,
                             char *SV, npy_intp *SV_dims,
                             char *support, npy_intp *support_dims,
@@ -204,6 +208,7 @@ model_error:
 /*
  * Get the number of support vectors in a model.
  */
+static
 npy_intp get_l(struct svm_model *model)
 {
     return (npy_intp) model->l;
@@ -213,6 +218,7 @@ npy_intp get_l(struct svm_model *model)
  * Get the number of classes in a model, = 2 in regression/one class
  * svm.
  */
+static
 npy_intp get_nr(struct svm_model *model)
 {
     return (npy_intp) model->nr_class;
@@ -223,6 +229,7 @@ npy_intp get_nr(struct svm_model *model)
  * model->sv_coef is a double **, whereas data is just a double *,
  * so we have to do some stupid copying.
  */
+static
 void copy_sv_coef(char *data, struct svm_model *model)
 {
     int i, len = model->nr_class-1;
@@ -233,6 +240,7 @@ void copy_sv_coef(char *data, struct svm_model *model)
     }
 }
 
+static
 void copy_intercept(char *data, struct svm_model *model, npy_intp *dims)
 {
     /* intercept = -rho */
@@ -262,6 +270,7 @@ void copy_SV(char *data, struct svm_model *model, npy_intp *dims)
     }
 }
 
+static
 void copy_support (char *data, struct svm_model *model)
 {
     memcpy (data, model->sv_ind, (model->l) * sizeof(int));
@@ -271,17 +280,20 @@ void copy_support (char *data, struct svm_model *model)
  * copy svm_model.nSV, an array with the number of SV for each class
  * will be NULL in the case of SVR, OneClass
  */
+static
 void copy_nSV(char *data, struct svm_model *model)
 {
     if (model->label == NULL) return;
     memcpy(data, model->nSV, model->nr_class * sizeof(int));
 }
 
+static
 void copy_probA(char *data, struct svm_model *model, npy_intp * dims)
 {
     memcpy(data, model->probA, dims[0] * sizeof(double));
 }
 
+static
 void copy_probB(char *data, struct svm_model *model, npy_intp * dims)
 {
     memcpy(data, model->probB, dims[0] * sizeof(double));
@@ -356,7 +368,7 @@ int copy_predict_proba(char *predict, struct svm_model *model, npy_intp *predict
  * sharing happens across objects (they *must* be called in the
  * correct order)
  */
-
+static
 int free_model(struct svm_model *model)
 {
     /* like svm_free_and_destroy_model, but does not free sv_coef[i] */
@@ -377,6 +389,7 @@ int free_model(struct svm_model *model)
     return 0;
 }
 
+static
 int free_param(struct svm_parameter *param)
 {
     if (param == NULL) return -1;
@@ -395,6 +408,7 @@ static void print_string_stdout(const char *s)
 }
 
 /* provide convenience wrapper */
+static
 void set_verbosity(int verbosity_flag){
 	if (verbosity_flag)
 		svm_set_print_string_function(&print_string_stdout);
--- contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/libsvm_sparse_helper.c	(index)
+++ contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/libsvm_sparse_helper.c	(working tree)
@@ -6,6 +6,7 @@
 /*
  * Convert scipy.sparse.csr to libsvm's sparse data structure
  */
+static
 struct svm_csr_node **csr_to_libsvm (double *values, int* indices, int* indptr, npy_int n_samples)
 {
     struct svm_csr_node **sparse, *temp;
@@ -40,7 +41,7 @@ struct svm_csr_node **csr_to_libsvm (double *values, int* indices, int* indptr, 
 }
 
 
-
+static
 struct svm_parameter * set_parameter(int svm_type, int kernel_type, int degree,
 		double gamma, double coef0, double nu, double cache_size, double C,
 		double eps, double p, int shrinking, int probability, int nr_weight,
@@ -76,6 +77,7 @@ struct svm_parameter * set_parameter(int svm_type, int kernel_type, int degree,
  *
  * TODO: precomputed kernel.
  */
+static
 struct svm_csr_problem * csr_set_problem (char *values, npy_intp *n_indices,
 		char *indices, npy_intp *n_indptr, char *indptr, char *Y,
                 char *sample_weight, int kernel_type) {
@@ -98,6 +100,7 @@ struct svm_csr_problem * csr_set_problem (char *values, npy_intp *n_indices,
 }
 
 
+static
 struct svm_csr_model *csr_set_model(struct svm_parameter *param, int nr_class,
                             char *SV_data, npy_intp *SV_indices_dims,
                             char *SV_indices, npy_intp *SV_indptr_dims,
@@ -203,6 +206,7 @@ model_error:
 /*
  * Copy support vectors into a scipy.sparse.csr matrix
  */
+static
 int csr_copy_SV (char *data, npy_intp *n_indices,
 		char *indices, npy_intp *n_indptr, char *indptr,
 		struct svm_csr_model *model, int n_features)
@@ -227,6 +231,7 @@ int csr_copy_SV (char *data, npy_intp *n_indices,
 }
 
 /* get number of nonzero coefficients in support vectors */
+static
 npy_intp get_nonzero_SV (struct svm_csr_model *model) {
 	int i, j;
 	npy_intp count=0;
@@ -310,11 +315,13 @@ int csr_copy_predict_proba (npy_intp *data_size, char *data, npy_intp *index_siz
 }
 
 
+static
 npy_intp get_nr(struct svm_csr_model *model)
 {
     return (npy_intp) model->nr_class;
 }
 
+static
 void copy_intercept(char *data, struct svm_csr_model *model, npy_intp *dims)
 {
     /* intercept = -rho */
@@ -328,6 +335,7 @@ void copy_intercept(char *data, struct svm_csr_model *model, npy_intp *dims)
     }
 }
 
+static
 void copy_support (char *data, struct svm_csr_model *model)
 {
     memcpy (data, model->sv_ind, (model->l) * sizeof(int));
@@ -338,6 +346,7 @@ void copy_support (char *data, struct svm_csr_model *model)
  * model->sv_coef is a double **, whereas data is just a double *,
  * so we have to do some stupid copying.
  */
+static
 void copy_sv_coef(char *data, struct svm_csr_model *model)
 {
     int i, len = model->nr_class-1;
@@ -351,11 +360,13 @@ void copy_sv_coef(char *data, struct svm_csr_model *model)
 /*
  * Get the number of support vectors in a model.
  */
+static
 npy_intp get_l(struct svm_csr_model *model)
 {
     return (npy_intp) model->l;
 }
 
+static
 void copy_nSV(char *data, struct svm_csr_model *model)
 {
     if (model->label == NULL) return;
@@ -372,11 +383,13 @@ void copy_label(char *data, struct svm_csr_model *model)
     memcpy(data, model->label, model->nr_class * sizeof(int));
 }
 
+static
 void copy_probA(char *data, struct svm_csr_model *model, npy_intp * dims)
 {
     memcpy(data, model->probA, dims[0] * sizeof(double));
 }
 
+static
 void copy_probB(char *data, struct svm_csr_model *model, npy_intp * dims)
 {
     memcpy(data, model->probB, dims[0] * sizeof(double));
@@ -388,6 +401,7 @@ void copy_probB(char *data, struct svm_csr_model *model, npy_intp * dims)
  * sharing happens across objects (they *must* be called in the
  * correct order)
  */
+static
 int free_problem(struct svm_csr_problem *problem)
 {
     int i;
@@ -399,6 +413,7 @@ int free_problem(struct svm_csr_problem *problem)
     return 0;
 }
 
+static
 int free_model(struct svm_csr_model *model)
 {
     /* like svm_free_and_destroy_model, but does not free sv_coef[i] */
@@ -415,6 +430,7 @@ int free_model(struct svm_csr_model *model)
     return 0;
 }
 
+static
 int free_param(struct svm_parameter *param)
 {
     if (param == NULL) return -1;
--- contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/svm.cpp	(index)
+++ contrib/python/scikit-learn/py3/sklearn/svm/src/libsvm/svm.cpp	(working tree)
@@ -3124,7 +3124,7 @@ const char *PREFIX(check_parameter)(const PREFIX(problem) *prob, const svm_param
 		// filter samples with negative and null weights 
 		remove_zero_weight(&newprob, prob);
 
-		char* msg = NULL;
+		const char* msg = NULL;
 		// all samples were removed
 		if(newprob.l == 0)
 			msg =  "Invalid input - all samples have zero or negative weights.";
--- contrib/python/scikit-learn/py3/sklearn/utils/src/MurmurHash3.h	(index)
+++ contrib/python/scikit-learn/py3/sklearn/utils/src/MurmurHash3.h	(working tree)
@@ -10,7 +10,7 @@
 
 // Microsoft Visual Studio
 
-#if defined(_MSC_VER)
+#if defined(_MSC_VER) && !defined(__clang__)
 
 typedef unsigned char uint8_t;
 typedef unsigned long uint32_t;
